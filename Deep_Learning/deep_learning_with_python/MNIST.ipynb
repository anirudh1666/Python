{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMmdj/wHqWASgStmHuHBl2R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anirudh1666/Python/blob/master/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwwNvqd6FaVP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOWy-HQfFb7H",
        "colab_type": "text"
      },
      "source": [
        "This notebook contains code for training an AI on the MNIST dataset to classify handwritten digits.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nepibx3nDjOm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "4cecbf24-e66b-472f-ba05-dc5bb9493d84"
      },
      "source": [
        "import keras \n",
        "from keras.datasets import mnist\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Load data from MNIST dataset. There are 60000 train_images and 10000 test_images.\n",
        "# First we must prepare the input data to match our needs.\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Reshape train_images into 2D tensor with 60000 samples and 28 * 28 features.\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "\n",
        "# We turn it into float32 then divide by 255 because we want each pixel value to be\n",
        "# a float inbetween 0 - 1. The max pixel value is 255.\n",
        "train_images = train_images.astype('float32') / 255\n",
        "train_labels = to_categorical(train_labels)\n",
        "\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "# We are using a linear layer structure so we use Sequential architecture\n",
        "network = models.Sequential()\n",
        "\n",
        "# Add two densely-connected layers that apply tensor operations to input data.\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "\n",
        "# Returns probability scores for each digit. They sum to 1.\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# categorical_crossentroy is loss function. rmsprop specifies to use mini\n",
        "# batch stochastical gradient based descent. \n",
        "network.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# This is the trianing loop. The network iterates over batches of 128 samples\n",
        "# 5 times over.\n",
        "network.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.2534 - accuracy: 0.9263\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.1037 - accuracy: 0.9696\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0674 - accuracy: 0.9798\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0491 - accuracy: 0.9851\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 2s 31us/step - loss: 0.0377 - accuracy: 0.9891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f1e501eff28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    }
  ]
}