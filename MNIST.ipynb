{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOW+BSKURqr3UGzhtKRG7dY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anirudh1666/Python/blob/master/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwwNvqd6FaVP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOWy-HQfFb7H",
        "colab_type": "text"
      },
      "source": [
        "This notebook contains code for training an AI on the MNIST dataset to classify handwritten digits.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nepibx3nDjOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras \n",
        "from keras.datasets import mnist\n",
        "\n",
        "# Load data from MNIST dataset. There are 60000 train_images and 10000 test_images.\n",
        "# First we must prepare the input data to match our needs.\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Reshape train_images into 2D tensor with 60000 samples and 28 * 28 features.\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "\n",
        "# We turn it into float32 then divide by 255 because we want each pixel value to be\n",
        "# a float inbetween 0 - 1. The max pixel value is 255.\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "# We are using a linear layer structure so we use Sequential architecture\n",
        "network = models.Sequential()\n",
        "\n",
        "# Add two densely-connected layers that apply tensor operations to input data.\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "\n",
        "# Returns probability scores for each digit. They sum to 1.\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# categorical_crossentroy is loss function. rmsprop specifies to use mini\n",
        "# batch stochastical gradient based descent. \n",
        "network.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# This is the trianing loop. The network iterates over batches of 128 samples\n",
        "# 5 times over.\n",
        "network.fit(train_images, train_labels, epochs=5, batch_size=128)J\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}